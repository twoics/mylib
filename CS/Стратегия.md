
## Рекурсия

	Механизм когда функция вызывает сама себя во время выполнения

Такие алгоритмы имеют **базовые случаи** - когда входные данные удовлетворяют какому-либо условию, и вместо вызова самой себя с некоторым значением она возвращает какой-то **результат**, который передается выше по стеку вызовов

##### Рекурсия VS Итерация

Рекурсивные алгоритмы **проще** итеративных (для понимания)
Но
- Они порождают много копий самих себя, это требует **большего** объема **памяти**
- Можно дойти до порога стека рекурсии
- Довольно просто упустить условие остановки, что опять же, вызовет переполнение стека

##### Подходит
- Когда задача сама собой разбивается на более мелкие того же типа 
- Для обхода графовых структур

##### Пример

```python
def summ(n: int) -> int:
    if n <= 2:
        return 1
    return summ(n - 2) + summ(n - 1)
```

## Полный перебор

	Исчерпывающий поиск. Проверяет ВСЕ возможные варианты, опирается только на
	силу. 

**Плюсы**
- Простота написания и понимания
- Могут решать NP-полные задачи

**Минусы**
- Вариантов с каждым элементом растет что пиздец
- Коллеги за такое могут перестать здороваться

## Поиск с возвратом

	Вариант поиска, заключается в переборе последующих шагов, и в случае, если ни
	один из шагов не ведет к положительному результату, мы делаем шаг назад

Лучше всего подходит для задач, где нужно получить **последовательность** вариантов (при этом **не важно** получить самую оптимальную (допустим короткую) последовательность - мы должны только **найти** решение), и выбор каждого нового варианта, **накладывает ограничения на** выбор следующих вариантов.

	Этот алгоритм часто выполняют в виде рекурсии

![[Pasted image 20240328112402.png]]

#### Пример

	Задача с размещением 8 ферзей на шахматной доске, чтобы ни один не 
	смог срубить другого

## Эвристические алгоритмы 

	Семейство алгоритмов, которые решают какую-то задачу достаточно хорошим 
	образом, но, возможно, не самым оптимальным

Эвристические алгоритмы **не гарантируют**, что найденное ими решение - самое оптимальные

### Жадные алгоритмы

	Как пример эвристических алгоритмов - жадный алгоритм

На каждой итерации, он берет **самое выгодное** в **данный момент** решение. Он никогда не откатиться к предыдущему состоянию.

	Условно это ультрагигачад который жестко уверен в своих действиях, и берет 
	самое ценное от жизни

**Плюсы**
- Для некоторых задач он подходит идеально
- В среднем, предлагает довольно неплохое решение
- Простая реализация

**Минусы**
- Выбранное решение, может быть менее точным, чем реальное _(задача с вором и слитками золота разного размера)_

##### А надо оно ?
Перед тем как упарываться в точность, стоит подумать, **для конкретной** задачи действительна нужна более высокая точность ? 

#### Пример

	Задача с поиском наибольшей выгоды для вора, который крадет слитки золота 
	(разного размера) и кладет их в свой (ограниченный размером) рюкзак


## Разделяй и властвуй

	Я думаю не стоит говорить в чем этот прицип. Он уже оверхайпед

#### Пример

	Как пример могу привести сортировку слиянием, тут ниже простая ее версия
	без алгоритма слияния для экономии места

```python
def merge(list1, list2) -> list:  
    """  
    Тут типа происходит итерация по двум массивам
    Так как они отсортированы то их элементы можно сравнивать по-очереди  
    
    Делаем указатели на первые элементы массивов.
    Сравниваем элементы по указателям, тот что меньше добавляем в результат
    и указатель сдвигаем вправо у него
    
    Если один из указателей вышел за границы своего массива
    то остальные элементы пушим в результат  
    """    return sorted(list1 + list2)
  
  
def merge_sort(l: list) -> list:  
    if len(l) == 1:  
        return l  
  
    mid = len(l) // 2  
    left = merge_sort(l[:mid])  
    right = merge_sort(l[mid:])  
    return merge(merge_sort(left), merge_sort(right))
```


## Динамическое программирование

	Это метод решения задач, в которм задача бьётся на подзадачи, при
	этом результат каждой подзадачи сохраняется, чтобы не выполнять 
	повторный расчет

Иначе этот прием называется **мемоизация**


## Метод верхних и нижних границ

	TODO факультативно покопаться в нем

На сейчас, что я понял, метод для каждого шага берет все переходы из него, **сравнивает по стоимости** переходы и отсеивает слишком дорогие

Это очень сильно напоминает жадный алгоритм, **надо в этом детальнее покопаться**

